---
title: Understanding the New User Experience in Buffer
author: Julian Winternheimer
date: '2022-04-06'
slug: []
categories: []
tags: []
---

We'd like to gain a better understand our new user journey within Buffer and document its current performance.In doing so, we'd like to be able to answer the following questions:

 1. What is the elasticity of our signup-to-customer conversion rate for cohorts starting in Trial when we increase volume?

 2. Does defaulting new signups to Trial increase their exposure and usage of our pay-walled features like Analyze?

 3. What improvements can be made to the 14-Day Trial period for less qualified users? 
 
```{r include = FALSE, message = FALSE, warning = FALSE}
# load libraries
library(buffer)
library(lubridate)
library(dplyr)
library(ggplot2)
library(scales)
library(tidyr)
library(glmnet)
library(survival)
library(survminer)
library(ggfortify)
```
 


## Data Collection
We'll collect the approximately 1M signups that occurred since January 1, 2021.

```{r eval = FALSE, warning = FALSE, message = FALSE}
# define sql query
sql <- "
  with users as (
    select
      u.user_id
      , u.stripe_customer_id
      , u.signup_at_date
      , date_trunc(u.signup_at_date, week) as signup_week
      , u.did_signup_from_mobile as mobile_signup
      , u.is_team_member
      , u.is_currently_trialing
      , u.did_signup_on_trial as trial_signup
      , date(min(a.timestamp)) as activated_at
      , date(min(s.first_paid_invoice_created_at)) as converted_date
      , count(distinct ss.session_id) as sessions_14_days
      , count(distinct a.id) as actions
      , count(distinct a.date) as days_active
      , count(distinct case when a.product = 'publish' then a.id end) as publish_actions
      , count(distinct case when a.product = 'analyze' then a.id end) as analyze_actions
      , count(distinct case when a.product = 'engage' then a.id end) as engage_actions
      , count(distinct case when a.product = 'start_pages' then a.id end) as sp_actions
    from dbt_buffer.buffer_users as u
    left join dbt_buffer.buffer_key_actions as a
      on u.user_id = a.user_id
      and a.timestamp >= u.signup_at
      and a.timestamp <= timestamp_add(u.signup_at, interval 14 day)
    left join dbt_buffer.stripe_paid_subscriptions as s
      on u.stripe_customer_id = s.customer_id
      and s.first_paid_invoice_created_at >= u.signup_at
    left join dbt_buffer.segment_sessions as ss
      on ss.dbt_visitor_id = u.user_id
      and ss.started_at >= u.signup_at
      and date(ss.started_at) <= date_add(u.signup_at_date, interval 14 day)
    where u.signup_at >= '2021-01-01'
    group by 1,2,3,4,5,6,7,8
  )
  
  select * from users
"

# collect data from bigquery
users <- bq_query(sql = sql)

# save data
saveRDS(users, "trial_analysis_users.rds")
```

```{r include = FALSE}
# read data
users <- readRDS("trial_analysis_users.rds") %>% 
  mutate(converted_30day = (!is.na(converted_date) & 
           as.numeric(converted_date - signup_at_date) <= 30),
         converted = !is.na(converted_date))
```


## Baseline Conversion Rates
Let's start by calculating the proportion of free and trial signups that subscribed to a paid plan within 30 days of signing up.

```{r warning = FALSE, message = FALSE}
# calculate conversion rates
users %>% 
  filter(signup_week < "2022-03-01" & (is.na(mobile_signup) | !mobile_signup)) %>% 
  group_by(trial_signup, converted_30day) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = percent(users / sum(users), accuracy = 0.01)) %>% 
  filter(converted_30day)
```

Approximately 0.8% of free web signups convert within 30 days, compared to 5.2% of trial signups. This includes users that signed up that were automatically put onto trials. This trend is relatively stable over time.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rates over time
users %>% 
  filter((is.na(mobile_signup) | !mobile_signup)) %>% 
  group_by(signup_week, trial_signup, converted_30day) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  filter(converted_30day & signup_week < "2022-03-01") %>% 
  buffplot(aes(x = signup_week, y = percent, color = trial_signup)) +
  geom_line() +
  scale_y_continuous(labels = percent) +
  labs(x = "Signup Week", y = "30-Day Conversion Rate",
       color = "Trial Signup")
```


## Distribution of Time to Conversion
Next we'll analyze the distributions of the number of days it takes new signups to convert to a paid plan. We can start by calculating quantiles for trial and free users.

```{r}
#define quantiles of interest
q = c(.25, .5, .75)

#calculate quantiles by grouping variable
users %>%
  filter(converted & (is.na(mobile_signup) | !mobile_signup)) %>% 
  mutate(days_to_convert = as.numeric(converted_date - signup_at_date)) %>% 
  group_by(trial_signup) %>%
  summarize(quant25 = quantile(days_to_convert, probs = q[1]), 
            quant50 = quantile(days_to_convert, probs = q[2]),
            quant75 = quantile(days_to_convert, probs = q[3]))
```

These quantiles show us that the median number of days to convert is 14 days for trial signups and 18 days for free signups. It's interesting to note that more than a quarter of the people that convert do so by thier second day. We should remember that this only takes into account users that converted. 

We can plot the distribution of the number of days to convert below.

```{r echo = FALSE, warning = FALSE, message = FALSE}
#calculate quantiles by grouping variable
users %>%
  filter(converted & (is.na(mobile_signup) | !mobile_signup)) %>% 
  mutate(days_to_convert = as.numeric(converted_date - signup_at_date)) %>% 
  filter(days_to_convert >= 0) %>% 
  group_by(trial_signup, days_to_convert) %>% 
  summarise(customers = n_distinct(stripe_customer_id)) %>% 
  mutate(percent = customers / sum(customers)) %>% 
  buffplot(aes(x = days_to_convert, y = percent, fill = trial_signup)) +
  geom_col(show.legend = FALSE) +
  scale_x_continuous(limits = c(0, 60)) +
  facet_wrap(~trial_signup, nrow = 1) +
  scale_y_continuous(labels = percent) +
  labs(x = "Days to Convert", y = "Percent of Conversions", fill = "Trial Signup")
```

A higher proportion of free signups convert on the day that they sign up, and more conversions are clustered around the 14-day mark (the length of the trial) for trial signups.

## Survival Analysis
Because a greater proportion of trialists end up converting, it could be worth using survival analysis techniques to visualize the amount of time it takes to convert.

```{r}
# set status column
users <- users %>% 
  mutate(status = ifelse(converted, 1, 0),
         time = ifelse(
           converted, as.numeric(converted_date - signup_at_date),
           as.numeric(Sys.Date() - signup_at_date)))

# fit survival curve
fit.surv <- survfit(Surv(time, status) ~ trial_signup, data = users)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
# plot survival curve
autoplot(fit.surv, censor = TRUE, censor.size = 1) +
  scale_x_continuous(limits = c(0, 180), breaks = seq(0, 180, 30)) +
  scale_y_continuous(labels = percent) +
  labs(x = "Days Since Signup", y = "Estimated % That Hasn't Converted",
       title = "Survival Curve of Time to Convert",
       color = "Trial Signup",
       fill = "Trial Signup")
```

Each point on the graph represents the proportion of the population that _hasn't_ converted after X days. The inverse is the proportion that had converted by day X.

## Distribution of Number of Sessions
We can use a similar approach to calculate quantiles of the number of sessions in the first 14 days for free and trial users.

```{r}
#calculate quantiles by grouping variable
users %>%
  filter(is.na(mobile_signup) | !mobile_signup) %>% 
  mutate(days_to_convert = as.numeric(converted_date - signup_at_date)) %>% 
  group_by(converted, trial_signup) %>%
  summarize(quant25 = quantile(sessions_14_days, probs = q[1]), 
            quant50 = quantile(sessions_14_days, probs = q[2]),
            quant75 = quantile(sessions_14_days, probs = q[3]))
```

The distributions of the number of sessions in the first 14 days looks similar for free and trial signups.

```{r warning = FALSE, message = FALSE}
# define breakpoints 
breakpoints <- c(-Inf, 0, 1, 10, 25, 50, Inf)

# plot distributions
users %>%
  filter(is.na(mobile_signup) | !mobile_signup) %>% 
  mutate(session_bucket = cut(sessions_14_days, breaks = breakpoints),
         type = case_when(
          converted & trial_signup ~ "converted_trial",
          converted & !trial_signup ~ "converted_free",
          !converted & trial_signup ~ "no_conversion_trial",
          !converted & !trial_signup ~ "no_conversion_free",
          TRUE ~ "unknown"
  )) %>% 
  group_by(type, session_bucket) %>%
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  buffplot(aes(x = session_bucket, y = percent, fill = type)) +
  geom_col(show.legend = F) +
  facet_wrap(~type) +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) +
  labs(x = "Sessions First 14 Days", y = "Percent of Users")
```

We can see that users that convert to paid plans generally have more sessions in their first 14 days. The largest bucket of converted users had 10-25 sessions in their first 14 days.


## Web vs Mobile
It's important to note that mobile signups do not start on trials -- they all start on a free plan.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rates over time
users %>% 
  filter(!is.na(mobile_signup)) %>% 
  group_by(signup_week, mobile_signup, converted_30day) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  filter(converted_30day & signup_week < "2022-03-01") %>% 
  buffplot(aes(x = signup_week, y = percent, color = mobile_signup)) +
  geom_line() +
  scale_y_continuous(labels = percent) +
  labs(x = "Signup Week", y = "30-Day Conversion Rate",
       color = "Mobile Signup")
```

30-day conversion rates are generally much lower for people that sign up on mobile. Let's now compare conversion rates for web users that signed up without a trial.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rates over time
users %>% 
  filter(!is.na(mobile_signup) & !trial_signup) %>% 
  group_by(signup_week, mobile_signup, converted_30day) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  filter(converted_30day & signup_week < "2022-03-01") %>% 
  buffplot(aes(x = signup_week, y = percent, color = mobile_signup)) +
  geom_line() +
  scale_y_continuous(labels = percent) +
  labs(x = "Signup Week", y = "30-Day Conversion Rate",
       caption = "Free Signups Only",
       color = "Mobile Signup")
```

We can see that the conversion rates are much closer, but they're still higher for web signups.

## Key Actions and Upgrades
Let's see which key actions are most correlated with conversion.

```{r include = FALSE, warning = FALSE, message = FALSE}
# add boolean values for using products
users <- users %>% 
  mutate(used_publish = publish_actions > 0,
         used_engage = engage_actions > 0,
         used_analyze = analyze_actions > 0,
         used_sp = sp_actions > 0)
```

```{r warning = FALSE, message = FALSE}
# filter data
filtered <- users %>% select(converted, publish_actions:sp_actions)

# create correlation matrix
m <- cor(filtered)

# view matrix
head(round(m, 2))
```

We can see that the correlations are quite low, but this could be because the variance of the number of actions is quite high. For example, let's plot the distribution of the number of publish actions taken in the first 14 days.

```{r}
# plot dist of publish actions
users %>% 
  buffplot(aes(x = publish_actions, color = converted)) +
  stat_ecdf() +
  coord_cartesian(xlim = c(0, 500))
```

We can see that users that converted tended to take more publish actions than those that didn't convert. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
# filter data
filtered <- users %>% select(user_id, converted_30day:used_sp)

# pivot to long format
rates <- filtered %>% 
  rename(publish = used_publish,
         engage = used_engage,
         analyze = used_analyze,
         start_page = used_sp) %>% 
  pivot_longer(publish:start_page,
               names_to = "product",
               values_to = "did_use") %>% 
  group_by(product, did_use, converted_30day) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users))

# plot conversion rates by whether used
rates %>% 
  filter(converted_30day) %>% 
  buffplot(aes(x = did_use, y = percent, fill = product)) +
  geom_col(show.legend = F) +
  facet_wrap(~product) +
  scale_y_continuous(labels = percent, breaks = seq(0, 25, 0.05)) +
  labs(x = "Used in First 14 Days", y = "Conversion Rate")
```


The plot above shows us the conversion rates for those that did and did not use certain features in their first 14 days. We can see that users that use Analyze or Engage tend to convert at high rates, but not using those features doesn't necessarily mean that there's a low chance of conversion.

We can also bucket the number of actions taken in each product to visualize the correlations.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# filter data
filtered <- users %>% select(user_id, converted_30day, publish_actions:sp_actions)

# define breakpoints
breakpoints <- c(-Inf, 0, 5, 10, 25, 50, 100, Inf)

# pivot to long format
rates <- filtered %>% 
  rename(publish = publish_actions,
         engage = engage_actions,
         analyze = analyze_actions,
         start_page = sp_actions) %>% 
  pivot_longer(publish:start_page,
               names_to = "product",
               values_to = "actions") %>% 
  mutate(action_bucket = cut(actions, breaks = breakpoints)) %>% 
  group_by(product, action_bucket, converted_30day) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users))

# plot conversion rates by whether used
rates %>% 
  filter(converted_30day) %>% 
  buffplot(aes(x = action_bucket, y = percent, fill = product)) +
  geom_col(show.legend = F) +
  facet_wrap(~product, scales = "free_y") +
  scale_y_continuous(labels = percent) +
  labs(x = "Actions in First 14 Days", y = "Conversion Rate") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5))
```

The plots above show that there are indeed correlations between the number of key actions taken and conversion rates, which is unsurprising. 

## Lasso Regression
Lasso regression is a method we can use to fit a regression model when multicollinearity is present in the data.

In a nutshell, lasso regression shrinks the coefficients of predictors to 0 if they don't contribute enough to the model.

```{r}
# set new column
users <- users %>% mutate(response = ifelse(converted_30day, 1, 0))

# define response variable
y <- users$response

# define matrix of predictor variables
features <- users %>% 
  dplyr::select(mobile_signup, is_team_member, trial_signup,
                sessions_14_days, actions, days_active,used_publish, 
                used_engage, used_analyze, used_sp)

# turn strings into factors
features <- as.data.frame(unclass(features), stringsAsFactors = TRUE)

# create matrix
x <- as.matrix(features)
```

```{r}
# fit lasso regression model
mod <- cv.glmnet(x, y, alpha = 1)

# summarise model
coef(mod)
```

The lasso regression model suggests that using engage and analyze are predictive of conversions. After that, signing up with a trial, the number of days active, and the number of sessions in the first 14 days are the most predictive features.

We can also plot the relationship between the number of days active in the first 14 days and conversion rate.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rate by days active
users %>% 
  group_by(trial_signup, days_active, converted_30day) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(prop = users / sum(users)) %>% 
  filter(converted_30day) %>% 
  buffplot(aes(x = days_active, y = prop, fill = trial_signup)) +
  geom_col(show.legend = F) +
  facet_wrap(~trial_signup, scales = "free_y") +
  labs(x = "Days Active in First 14 Days", y = "Conversion Rate",
       fill = "Trial Signup") +
  scale_y_continuous(labels = percent)
```

Users that are active at least 5 days have a much higher likelihood of converting to a paid plan, especially if they signed up with a trial.

## Frequency of Login and Activation
To answer this question we'll need to collect more data. The data could be muddled because some users activate quickly, and activated users are more likely to log in. Additionally [80% of users that activate in their first 7 days do so within 12 hours of signing up](https://mixpanel.com/s/2HgEX). 

Let's look at the number of events in the first session and average session duration.

```{r eval = FALSE, warning = FALSE, message = FALSE}
# define sql query
sql <- "
  with users as (
    select
      u.user_id
      , u.stripe_customer_id
      , u.signup_at_date
      , date_trunc(u.signup_at_date, week) as signup_week
      , u.did_signup_from_mobile as mobile_signup
      , u.is_team_member
      , u.is_currently_trialing
      , u.did_signup_on_trial as trial_signup
      , date(min(a.timestamp)) as activated_at
      , date(min(s.first_paid_invoice_created_at)) as converted_date
      , count(distinct ss.session_id) as signup_sessions
      , avg(ss.n_events) as avg_sesh_events
      , avg(ss.session_duration_minutes) as avg_sesh_duration
    from dbt_buffer.buffer_users as u
    left join dbt_buffer.buffer_key_actions as a
      on u.user_id = a.user_id
      and a.timestamp >= u.signup_at
      and a.timestamp <= timestamp_add(u.signup_at, interval 14 day)
    left join dbt_buffer.stripe_paid_subscriptions as s
      on u.stripe_customer_id = s.customer_id
      and s.first_paid_invoice_created_at >= u.signup_at
    left join dbt_buffer.segment_sessions as ss
      on ss.dbt_visitor_id = u.user_id
      and ss.signup_session
      and date(ss.started_at) = date(u.signup_at)
    where u.signup_at >= '2021-01-01'
    group by 1,2,3,4,5,6,7,8
  )
  
  select * from users
"

# collect data from bigquery
activations <- bq_query(sql = sql)

# save data
saveRDS(activations, "trial_analysis_activations.rds")
```

```{r include = FALSE}
# read data
activations <- readRDS("trial_analysis_activations.rds") %>% 
  mutate(activated_day1 = as.numeric(converted_date - signup_at_date) <= 1 &
           !is.na(converted_date))
```

Let's show some summary stats for session length.

```{r}
# calculate quantiles by grouping variable
activations %>%
  filter(!is.na(avg_sesh_duration)) %>% 
  group_by(activated_day1) %>%
  summarize(quant25 = quantile(avg_sesh_duration, probs = q[1]), 
            quant50 = quantile(avg_sesh_duration, probs = q[2]),
            quant75 = quantile(avg_sesh_duration, probs = q[3]))
```

Those that activated on their first day tended to have much longer first sessions. The median session duration was 26 minutes, compared to 5 minutes for those that didn't activate. Let's now look at the number of events.

```{r}
# calculate quantiles by grouping variable
activations %>%
  filter(!is.na(avg_sesh_events)) %>% 
  group_by(activated_day1) %>%
  summarize(quant25 = quantile(avg_sesh_events, probs = q[1]), 
            quant50 = quantile(avg_sesh_events, probs = q[2]),
            quant75 = quantile(avg_sesh_events, probs = q[3]))
```

Again, users that activated in their first day tended to have more events in their first session, which makes sense if the session was longer.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# define breakpoints
cuts <- c(0, 1, 5, 10, 30, 60, 90, Inf)

# plot distribution of session length
activations %>%
  filter(!is.na(avg_sesh_duration)) %>% 
  mutate(duration_bucket = cut(avg_sesh_duration, breaks = cuts)) %>% 
  filter(!is.na(duration_bucket)) %>% 
  group_by(activated_day1, duration_bucket) %>% 
  summarise(users = n_distinct(user_id)) %>%
  mutate(prop = users / sum(users)) %>% 
  buffplot(aes(x = duration_bucket, y = prop, fill = activated_day1)) +
  geom_col(show.legend = F) +
  facet_wrap(~activated_day1) +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) +
  labs(x = "First Session Duration", y = "Proportion of Users", 
       subtitle = "Activated on First Day")
```

```{r echo = FALSE, warning = FALSE, message = FALSE}
# define breakpoints
cuts <- c(0, 1, 5, 10, 30, 60, 90, Inf)

# plot distribution of session length
activations %>%
  filter(!is.na(avg_sesh_duration)) %>% 
  mutate(duration_bucket = cut(avg_sesh_duration, breaks = cuts)) %>% 
  filter(!is.na(duration_bucket)) %>% 
  group_by(duration_bucket, activated_day1) %>% 
  summarise(users = n_distinct(user_id)) %>%
  mutate(prop = users / sum(users)) %>% 
  filter(activated_day1) %>% 
  buffplot(aes(x = duration_bucket, y = prop)) +
  geom_col(show.legend = F) +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) +
  labs(x = "First Session Duration", y = "Proportion of Users", 
       subtitle = "Activated on First Day")
```

We can see that there is a strong correlation between first session duration and the likelihood of activating on the first day. Let's look at the relationship between first session length and the likelihood of conversion.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# join session length
sesh_length <- activations %>% select(user_id, avg_sesh_duration)

# join to users
users <- users %>% 
  left_join(sesh_length, by = "user_id")

# plot distribution of session length
users %>%
  filter(!is.na(avg_sesh_duration)) %>% 
  mutate(duration_bucket = cut(avg_sesh_duration, breaks = cuts)) %>% 
  filter(!is.na(duration_bucket)) %>% 
  group_by(duration_bucket, converted) %>% 
  summarise(users = n_distinct(user_id)) %>%
  mutate(prop = users / sum(users)) %>% 
  filter(converted) %>% 
  buffplot(aes(x = duration_bucket, y = prop)) +
  geom_col(show.legend = F) +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) +
  labs(x = "First Session Duration", y = "Proportion of Users", 
       subtitle = "Converted to Paid Subscription")
```

We can see that there is a clear correlation with conversion as well.

## Upgrade Paths
Next we'll look at upgrade paths.The data used in the analysis below comes from [this Mixpanel report](https://mixpanel.com/s/4DPzTa) and only includes upgrade paths that have been defined in the `Upgrade Path Viewed` tracking event.

```{r include = FALSE, warning = FALSE, message = FALSE, eval = FALSE}
library(readr)

# read csv
paths <- read_csv("~/Desktop/upgrade_paths.csv")

# clean data
names(paths) <- c("week", "upgrade_path", "views", "conversions")

# remove $ character
paths$upgrade_path <- gsub("\\$", "", paths$upgrade_path)

# save data
saveRDS(paths, "upgrade_paths.rds")
```

```{r include = FALSE}
# read data
paths <- readRDS("upgrade_paths.rds")
```

We'll start by looking at the number of conversions each path drives each week. All of the conversions must occur within 7 days of viewing the upgrade path.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversions by upgrade path
paths %>% 
  filter(upgrade_path != "overall" & 
           upgrade_path != "app-shell-userMenu-upgrade" &
           week >= "2021-07-01") %>% 
  mutate(upgrade_path = reorder(upgrade_path, -conversions)) %>% 
  buffplot(aes(x = week, y = conversions, color = upgrade_path)) +
  geom_line(size = 0.8) +
  facet_wrap(~upgrade_path, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "Week", y = "Conversions")
```

The upgrade path that stands out most clearly is `publish-profile-nav-tabNavigation-upgrade-1`. At one point it was driving over 200 upgrades per week, but it has since been changed to a prompt to start a trial. Now it drives only 5-15 upgrades per week.  

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversions by upgrade path
paths %>% 
  filter(upgrade_path == "publish-profile-nav-tabNavigation-upgrade-1") %>% 
  buffplot(aes(x = week, y = conversions)) +
  geom_line(size = 0.8) +
  theme(legend.position = "none") +
  labs(x = "Week", y = "Conversions", 
       title = "Conversions by Upgrade Path",
       subtitle = "Publish Nav Upgrade Button")
```


Another one that stands out is `publish-profileSidebar-addChannelButton-upgrade-1`. Upgrades from this path have also decreased by over 50%. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversions by upgrade path
paths %>% 
  filter(upgrade_path == "publish-profileSidebar-addChannelButton-upgrade-1") %>% 
  buffplot(aes(x = week, y = conversions)) +
  geom_line(size = 0.8) +
  theme(legend.position = "none") +
  labs(x = "Week", y = "Conversions", 
       title = "Conversions by Upgrade Path",
       subtitle = "Publish Sidebar Add Channel Button")
```

Next let's look at the conversion _rates_ of each upgrade path. The conversion rate is just the proportion of users that viewed an upgrade path and converted within 7 days of that event.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversions by upgrade path
paths %>% 
  filter(upgrade_path != "overall" & 
           upgrade_path != "app-shell-userMenu-upgrade" &
           week >= "2021-07-01") %>% 
  mutate(rate = conversions / views,
         upgrade_path = reorder(upgrade_path, -rate)) %>% 
  buffplot(aes(x = week, y = rate, color = upgrade_path)) +
  geom_line(size = 0.8) +
  scale_y_continuous(labels = percent) +
  facet_wrap(~upgrade_path, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "Week", y = "Conversion Rate")
```

Here are the top upgrade paths by conversion rate:

 - Queue limit
 - Campaigns empty state
 - Awaiting approval paywall
 - Top nav upgrade button
 - Add channel button
 - Hashtag manager path
 - Drafts paywall
 
Let's isolate a couple of these.
 
 
## Queue Limit and Channel Limit Upgrade Paths
This upgrade path has the highest conversion rate. Around 140-160 users run into it each week.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversions by upgrade path
paths %>% 
  filter((upgrade_path == "publish-composer-profileQueueLimit-showPaidPlans-1" |
           upgrade_path == "publish-profileSidebar-addChannelButton-upgrade-1") &
           week <= "2022-04-01") %>% 
  buffplot(aes(x = week, y = views, color = upgrade_path)) +
  geom_line(size = 0.8) +
  labs(x = "Week", y = "Upgrade Path Viewers", 
       title = "Upgrade Path Viewers",
       subtitle = "Queue Limit and Channel Connection",
       color = NULL)
```

Many more users view the channel limit upgrade path, which is why it drives more conversions.
 
```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversions by upgrade path
paths %>% 
  filter((upgrade_path == "publish-composer-profileQueueLimit-showPaidPlans-1" |
           upgrade_path == "publish-profileSidebar-addChannelButton-upgrade-1") &
           week <= "2022-04-01") %>% 
  buffplot(aes(x = week, y = conversions, color = upgrade_path)) +
  geom_line(size = 0.8) +
  labs(x = "Week", y = "Upgrade Path Conversions", 
       title = "Upgrade Path Conversions",
       subtitle = "Queue Limit and Channel Connection",
       color = NULL)
```


## User Limit Upgrade Path
As of April 2022 we're not tracking a distinct upgrade path for the 1-user limit. I'd recommend tracking this upgrade path if it exists, and if it doesn't I'd recommend creating one. 

Right now the closest upgrade path we have would probably be `publish-awaitingApproval-paywall-upgrade-1`. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversions by upgrade path
paths %>% 
  filter((upgrade_path == "publish-awaitingApproval-paywall-upgrade-1") &
           week <= "2022-04-01") %>% 
  buffplot(aes(x = week)) +
  geom_line(aes(y = views, color = "Views"), size = 0.8) +
  geom_line(aes(y = conversions, color = "Conversions"), size = 0.8) +
  labs(x = "Week", y = "Users", 
       title = "Upgrade Path Conversions",
       subtitle = "Awaiting Approval Upgrade Path",
       color = NULL)
```


## Role of Analyze and Engage During Trial
Next we'll look at the role analyze and engage play during trials. The data used in this section of the analysis is gathered with the following SQL query. The data includes 180K trials started since September 2021 (after the New Buffer launch).

```{r eval = FALSE, warning = FALSE, message = FALSE}
# define sql query
sql <- "
  select
    t.id as trial_id
    , t.trial_started_at
    , t.subscription_id
    , t.customer_id
    , t.plan_id
    , t.metadata_user_id as trial_user_id
    , t.has_converted as converted
    , count(distinct a.id) as actions
    , count(distinct case when a.product = 'publish' then a.id end) as pub_actions
    , count(distinct case when a.product = 'engage' then a.id end) as engage_actions
    , count(distinct case when a.product = 'analyze' then a.id end) as analyze_actions
  from dbt_buffer.stripe_trials as t
  left join dbt_buffer.buffer_key_actions as a
    on t.metadata_user_id = a.user_id
    and a.timestamp > t.trial_started_at
    and a.timestamp < timestamp_add(t.trial_started_at, interval 14 day)
  where t.trial_started_at >= '2021-09-01'
  group by 1,2,3,4,5,6,7
"

# collect data from bigquery
trials <- bq_query(sql = sql)

# save data
saveRDS(trials, "trial_analysis_trials.rds")
```

```{r include = FALSE}
# read data
trials <- readRDS("trial_analysis_trials.rds")

# determine if active
trials <- trials %>% 
  mutate(active = actions >= 1,
         publish_active = pub_actions > 0,
         analyze_active = analyze_actions > 0,
         engage_active = engage_actions > 0) 
```

One quick approach we could take is to fit a logistic regression model to see if using each of the features is correlated with trial conversion _given that the user was active during trial_. It's important to note that there's likely collinearity, which is why some regularization or feature selection is important.

```{r}
# fit logistic regression model
mod <- glm(converted ~ active + publish_active + engage_active + analyze_active,
           data = trials, family = "binomial")

# summarise model
summary(mod)
```

The use of each feature is correlated with success. We can try using lasso regression again.

```{r}
# set new column
trials <- trials %>% mutate(response = ifelse(converted, 1, 0))

# define response variable
y <- trials$response

# define matrix of predictor variables
features <- trials %>% 
  dplyr::select(active:engage_active)

# turn strings into factors
features <- as.data.frame(unclass(features), stringsAsFactors = TRUE)

# create matrix
x <- as.matrix(features)
```

```{r}
# fit lasso regression model
mod <- cv.glmnet(x, y, alpha = 1)

# summarise model
coef(mod)
```

All features are correlated with conversion, which isn't surprising. However, using Engage seems to be indicative of a much greater likelihood of converting.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# filter data
filtered <- trials %>% select(customer_id, converted, active:engage_active)

# pivot to long format
rates <- filtered %>% 
  rename(publish = publish_active,
         engage = engage_active,
         analyze = analyze_active,
         all_buffer = active) %>% 
  pivot_longer(all_buffer:engage,
               names_to = "product",
               values_to = "did_use") %>% 
  group_by(product, did_use, converted) %>% 
  summarise(users = n_distinct(customer_id)) %>% 
  mutate(percent = users / sum(users))

# plot conversion rates by whether used
rates %>% 
  filter(converted) %>% 
  buffplot(aes(x = did_use, y = percent, fill = product)) +
  geom_col(show.legend = F) +
  facet_wrap(~product) +
  scale_y_continuous(labels = percent) +
  labs(x = "Used During Trial", y = "Conversion Rate")
```

