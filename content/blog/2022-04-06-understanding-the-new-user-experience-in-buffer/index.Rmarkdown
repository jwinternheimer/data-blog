---
title: Understanding the New User Experience in Buffer
author: Julian Winternheimer
date: '2022-04-06'
slug: []
categories: []
tags: []
---

We'd like to gain a better understand our new user journey within Buffer and document its current performance.In doing so, we'd like to be able to answer the following questions:

 1. What is the elasticity of our signup-to-customer conversion rate for cohorts starting in Trial when we increase volume?

 2. Does defaulting new signups to Trial increase their exposure and usage of our pay-walled features like Analyze?

 3. What improvements can be made to the 14-Day Trial period for less qualified users? 
 
```{r include = FALSE, message = FALSE, warning = FALSE}
# load libraries
library(buffer)
library(lubridate)
library(dplyr)
library(ggplot2)
library(scales)
library(tidyr)
library(glmnet)
```
 


## Data Collection
We'll collect the approximately 1M signups that occurred since January 1, 2021.

```{r eval = FALSE, warning = FALSE, message = FALSE}
# define sql query
sql <- "
  with users as (
    select
      u.user_id
      , u.stripe_customer_id
      , u.signup_at_date
      , date_trunc(u.signup_at_date, week) as signup_week
      , u.did_signup_from_mobile as mobile_signup
      , u.is_team_member
      , u.is_currently_trialing
      , u.did_signup_on_trial as trial_signup
      , date(min(a.timestamp)) as activated_at
      , date(min(s.first_paid_invoice_created_at)) as converted_date
      , count(distinct ss.session_id) as sessions_14_days
      , count(distinct a.id) as actions
      , count(distinct a.date) as days_active
      , count(distinct case when a.product = 'publish' then a.id end) as publish_actions
      , count(distinct case when a.product = 'analyze' then a.id end) as analyze_actions
      , count(distinct case when a.product = 'engage' then a.id end) as engage_actions
      , count(distinct case when a.product = 'start_pages' then a.id end) as sp_actions
    from dbt_buffer.buffer_users as u
    left join dbt_buffer.buffer_key_actions as a
      on u.user_id = a.user_id
      and a.timestamp >= u.signup_at
      and a.timestamp <= timestamp_add(u.signup_at, interval 14 day)
    left join dbt_buffer.stripe_paid_subscriptions as s
      on u.stripe_customer_id = s.customer_id
      and s.first_paid_invoice_created_at >= u.signup_at
    left join dbt_buffer.segment_sessions as ss
      on ss.dbt_visitor_id = u.user_id
      and ss.started_at >= u.signup_at
      and date(ss.started_at) <= date_add(u.signup_at_date, interval 14 day)
    where u.signup_at >= '2021-01-01'
    group by 1,2,3,4,5,6,7,8
  )
  
  select * from users
"

# collect data from bigquery
users <- bq_query(sql = sql)

# save data
saveRDS(users, "trial_analysis_users.rds")
```

```{r include = FALSE}
# read data
users <- readRDS("trial_analysis_users.rds") %>% 
  mutate(converted = !is.na(converted_date) & 
           as.numeric(converted_date - signup_at_date) <= 30)
```


## Baseline Conversion Rates
Let's start by calculating the proportion of free and trial signups that subscribed to a paid plan within 30 days of signing up.

```{r warning = FALSE, message = FALSE}
# calculate conversion rates
users %>% 
  filter(signup_week < "2022-03-01" & (is.na(mobile_signup) | !mobile_signup)) %>% 
  group_by(trial_signup, converted) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = percent(users / sum(users), accuracy = 0.01)) %>% 
  filter(converted)
```

Approximately 0.8% of free web signups convert within 30 days, compared to 5.2% of trial signups. This includes users that signed up that were automatically put onto trials. This trend is relatively stable over time.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rates over time
users %>% 
  filter((is.na(mobile_signup) | !mobile_signup)) %>% 
  group_by(signup_week, trial_signup, converted) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  filter(converted & signup_week < "2022-03-01") %>% 
  buffplot(aes(x = signup_week, y = percent, color = trial_signup)) +
  geom_line() +
  scale_y_continuous(labels = percent) +
  labs(x = "Signup Week", y = "30-Day Conversion Rate",
       color = "Trial Signup")
```


## Distribution of Time to Conversion
Next we'll analyze the distributions of the number of days it takes new signups to convert to a paid plan. We can start by calculating quantiles for trial and free users.

```{r}
#define quantiles of interest
q = c(.25, .5, .75)

#calculate quantiles by grouping variable
users %>%
  filter(converted & (is.na(mobile_signup) | !mobile_signup)) %>% 
  mutate(days_to_convert = as.numeric(converted_date - signup_at_date)) %>% 
  group_by(trial_signup) %>%
  summarize(quant25 = quantile(days_to_convert, probs = q[1]), 
            quant50 = quantile(days_to_convert, probs = q[2]),
            quant75 = quantile(days_to_convert, probs = q[3]))
```

These quantiles show us that the median number of days to convert is 13 days for trial signups and 6 days for free signups. It's interesting to note that more than a quarter of the people that convert do so on the day they sign up. We should remember that this only takes into account users that converted. 

We can plot the distribution of the number of days to convert below.

```{r echo = FALSE, warning = FALSE, message = FALSE}
#calculate quantiles by grouping variable
users %>%
  filter(converted & (is.na(mobile_signup) | !mobile_signup)) %>% 
  mutate(days_to_convert = as.numeric(converted_date - signup_at_date)) %>% 
  filter(days_to_convert >= 0) %>% 
  group_by(trial_signup, days_to_convert) %>% 
  summarise(customers = n_distinct(stripe_customer_id)) %>% 
  mutate(percent = customers / sum(customers)) %>% 
  buffplot(aes(x = days_to_convert, y = percent, fill = trial_signup)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~trial_signup, nrow = 1) +
  scale_y_continuous(labels = percent) +
  labs(x = "Days to Convert", y = "Percent of Conversions", fill = "Trial Signup")
```

A higher proportion of free signups convert on the day that they sign up, and more conversions are clustered around the 14-day mark (the length of the trial) for trial signups.


## Distribution of Number of Sessions
We can use a similar approach to calculate quantiles of the number of sessions in the first 14 days for free and trial users.

```{r}
#calculate quantiles by grouping variable
users %>%
  filter(is.na(mobile_signup) | !mobile_signup) %>% 
  mutate(days_to_convert = as.numeric(converted_date - signup_at_date)) %>% 
  group_by(converted, trial_signup) %>%
  summarize(quant25 = quantile(sessions_14_days, probs = q[1]), 
            quant50 = quantile(sessions_14_days, probs = q[2]),
            quant75 = quantile(sessions_14_days, probs = q[3]))
```

The distributions of the number of sessions in the first 14 days looks similar for free and trial signups.

```{r warning = FALSE, message = FALSE}
# define breakpoints 
breakpoints <- c(-Inf, 0, 1, 10, 25, 50, Inf)

# plot distributions
users %>%
  filter(is.na(mobile_signup) | !mobile_signup) %>% 
  mutate(session_bucket = cut(sessions_14_days, breaks = breakpoints),
         type = case_when(
          converted & trial_signup ~ "converted_trial",
          converted & !trial_signup ~ "converted_free",
          !converted & trial_signup ~ "no_conversion_trial",
          !converted & !trial_signup ~ "no_conversion_free",
          TRUE ~ "unknown"
  )) %>% 
  group_by(type, session_bucket) %>%
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  buffplot(aes(x = session_bucket, y = percent, fill = type)) +
  geom_col(show.legend = F) +
  facet_wrap(~type) +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) +
  labs(x = "Sessions First 14 Days", y = "Percent of Users")
```

We can see that users that convert to paid plans generally have more sessions in their first 14 days. The largest bucket of converted users had 10-25 sessions in their first 14 days.

## Web vs Mobile
It's important to note that mobile signups do not start on trials -- they all start on a free plan.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rates over time
users %>% 
  filter(!is.na(mobile_signup)) %>% 
  group_by(signup_week, mobile_signup, converted) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  filter(converted & signup_week < "2022-03-01") %>% 
  buffplot(aes(x = signup_week, y = percent, color = mobile_signup)) +
  geom_line() +
  scale_y_continuous(labels = percent) +
  labs(x = "Signup Week", y = "30-Day Conversion Rate",
       color = "Mobile Signup")
```

30-day conversion rates are generally much lower for people that sign up on mobile. Let's now compare conversion rates for web users that signed up without a trial.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rates over time
users %>% 
  filter(!is.na(mobile_signup) & !trial_signup) %>% 
  group_by(signup_week, mobile_signup, converted) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users)) %>% 
  filter(converted & signup_week < "2022-03-01") %>% 
  buffplot(aes(x = signup_week, y = percent, color = mobile_signup)) +
  geom_line() +
  scale_y_continuous(labels = percent) +
  labs(x = "Signup Week", y = "30-Day Conversion Rate",
       caption = "Free Signups Only",
       color = "Mobile Signup")
```

We can see that the conversion rates are much closer, but they're still higher for web signups.

## Key Actions and Upgrades
Let's see which key actions are most correlated with conversion.

```{r include = FALSE, warning = FALSE, message = FALSE}
# add boolean values for using products
users <- users %>% 
  mutate(used_publish = publish_actions > 0,
         used_engage = engage_actions > 0,
         used_analyze = analyze_actions > 0,
         used_sp = sp_actions > 0)
```

```{r warning = FALSE, message = FALSE}
# filter data
filtered <- users %>% select(converted, publish_actions:sp_actions)

# create correlation matrix
m <- cor(filtered)

# view matrix
head(round(m, 2))
```

We can see that the correlations are quite low, but this could be because the variance of the number of actions is quite high. For example, let's plot the distribution of the number of publish actions taken in the first 14 days.

```{r}
# plot dist of publish actions
users %>% 
  buffplot(aes(x = publish_actions, color = converted)) +
  stat_ecdf() +
  coord_cartesian(xlim = c(0, 500))
```

We can see that users that converted tended to take more publish actions than those that didn't convert. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
# filter data
filtered <- users %>% select(user_id, converted:used_sp)

# pivot to long format
rates <- filtered %>% 
  rename(publish = used_publish,
         engage = used_engage,
         analyze = used_analyze,
         start_page = used_sp) %>% 
  pivot_longer(publish:start_page,
               names_to = "product",
               values_to = "did_use") %>% 
  group_by(product, did_use, converted) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users))

# plot conversion rates by whether used
rates %>% 
  filter(converted) %>% 
  buffplot(aes(x = did_use, y = percent, fill = product)) +
  geom_col(show.legend = F) +
  facet_wrap(~product) +
  scale_y_continuous(labels = percent, breaks = seq(0, 25, 0.05)) +
  labs(x = "Used in First 14 Days", y = "Conversion Rate")
```


The plot above shows us the conversion rates for those that did and did not use certain features in their first 14 days. We can see that users that use Analyze or Engage tend to convert at high rates, but not using those features doesn't necessarily mean that there's a low chance of conversion.

We can also bucket the number of actions taken in each product to visualize the correlations.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# filter data
filtered <- users %>% select(user_id, converted, publish_actions:sp_actions)

# define breakpoints
breakpoints <- c(-Inf, 0, 5, 10, 25, 50, 100, Inf)

# pivot to long format
rates <- filtered %>% 
  rename(publish = publish_actions,
         engage = engage_actions,
         analyze = analyze_actions,
         start_page = sp_actions) %>% 
  pivot_longer(publish:start_page,
               names_to = "product",
               values_to = "actions") %>% 
  mutate(action_bucket = cut(actions, breaks = breakpoints)) %>% 
  group_by(product, action_bucket, converted) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(percent = users / sum(users))

# plot conversion rates by whether used
rates %>% 
  filter(converted) %>% 
  buffplot(aes(x = action_bucket, y = percent, fill = product)) +
  geom_col(show.legend = F) +
  facet_wrap(~product, scales = "free_y") +
  scale_y_continuous(labels = percent) +
  labs(x = "Actions in First 14 Days", y = "Conversion Rate") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5))
```

The plots above show that there are indeed correlations between the number of key actions taken and conversion rates, which is unsurprising. 

## Lasso Regression
Lasso regression is a method we can use to fit a regression model when multicollinearity is present in the data.

In a nutshell, lasso regression shrinks the coefficients of predictors to 0 if they don't contribute enough to the model.

```{r}
# set new column
users <- users %>% mutate(response = ifelse(converted, 1, 0))

# define response variable
y <- users$response

# define matrix of predictor variables
features <- users %>% 
  dplyr::select(mobile_signup, is_team_member, trial_signup,
                sessions_14_days, actions, days_active,used_publish, 
                used_engage, used_analyze, used_sp)

# turn strings into factors
features <- as.data.frame(unclass(features), stringsAsFactors = TRUE)

# create matrix
x <- as.matrix(features)
```

```{r}
# fit lasso regression model
mod <- cv.glmnet(x, y, alpha = 1)

# summarise model
coef(mod)
```

The lasso regression model suggests that using engage and analyze are predictive of conversions. After that, signing up with a trial, the number of days active, and the number of sessions in the first 14 days are the most predictive features.

We can also plot the relationship between the number of days active in the first 14 days and conversion rate.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# plot conversion rate by days active
users %>% 
  group_by(trial_signup, days_active, converted) %>% 
  summarise(users = n_distinct(user_id)) %>% 
  mutate(prop = users / sum(users)) %>% 
  filter(converted) %>% 
  buffplot(aes(x = days_active, y = prop, fill = trial_signup)) +
  geom_col(show.legend = F) +
  facet_wrap(~trial_signup, scales = "free_y") +
  labs(x = "Days Active in First 14 Days", y = "Conversion Rate",
       fill = "Trial Signup") +
  scale_y_continuous(labels = percent)
```

Users that are active at least 5 days have a much higher likelihood of converting to a paid plan, especially if they signed up with a trial.

## Frequency of Login and Activation
To answer this question we'll need to collect more data. The data could be muddled because some users activate quickly, and activated users are more likely to log in. Additionally [80% of users that activate in their first 7 days do so within 12 hours of signing up](https://mixpanel.com/s/2HgEX). 

Let's look at the number of events in the first session and average session duration.

```{r eval = FALSE, warning = FALSE, message = FALSE}
# define sql query
sql <- "
  with users as (
    select
      u.user_id
      , u.stripe_customer_id
      , u.signup_at_date
      , date_trunc(u.signup_at_date, week) as signup_week
      , u.did_signup_from_mobile as mobile_signup
      , u.is_team_member
      , u.is_currently_trialing
      , u.did_signup_on_trial as trial_signup
      , date(min(a.timestamp)) as activated_at
      , date(min(s.first_paid_invoice_created_at)) as converted_date
      , count(distinct ss.session_id) as signup_sessions
      , avg(ss.n_events) as avg_sesh_events
      , avg(ss.session_duration_minutes) as avg_sesh_duration
    from dbt_buffer.buffer_users as u
    left join dbt_buffer.buffer_key_actions as a
      on u.user_id = a.user_id
      and a.timestamp >= u.signup_at
      and a.timestamp <= timestamp_add(u.signup_at, interval 14 day)
    left join dbt_buffer.stripe_paid_subscriptions as s
      on u.stripe_customer_id = s.customer_id
      and s.first_paid_invoice_created_at >= u.signup_at
    left join dbt_buffer.segment_sessions as ss
      on ss.dbt_visitor_id = u.user_id
      and ss.signup_session
      and date(ss.started_at) = date(u.signup_at)
    where u.signup_at >= '2021-01-01'
    group by 1,2,3,4,5,6,7,8
  )
  
  select * from users
"

# collect data from bigquery
activations <- bq_query(sql = sql)

# save data
saveRDS(activations, "trial_analysis_activations.rds")
```

```{r include = FALSE}
# read data
activations <- readRDS("trial_analysis_activations.rds") %>% 
  mutate(activated_day1 = as.numeric(converted_date - signup_at_date) <= 1 &
           !is.na(converted_date))
```

Let's show some summary stats for session length.

```{r}
# calculate quantiles by grouping variable
activations %>%
  filter(!is.na(avg_sesh_duration)) %>% 
  group_by(activated_day1) %>%
  summarize(quant25 = quantile(avg_sesh_duration, probs = q[1]), 
            quant50 = quantile(avg_sesh_duration, probs = q[2]),
            quant75 = quantile(avg_sesh_duration, probs = q[3]))
```

Those that activated on their first day tended to have much longer first sessions. The median session duration was 26 minutes, compared to 5 mintes for those that didn't activate. Let's now look at the number of events.

```{r}
# calculate quantiles by grouping variable
activations %>%
  filter(!is.na(avg_sesh_events)) %>% 
  group_by(activated_day1) %>%
  summarize(quant25 = quantile(avg_sesh_events, probs = q[1]), 
            quant50 = quantile(avg_sesh_events, probs = q[2]),
            quant75 = quantile(avg_sesh_events, probs = q[3]))
```

Again, users that activated in their first day tended to have more events in their first session, which makes sense if the session was longer.

```{r echo = FALSE, warning = FALSE, message = FALSE}
# define breakpoints
cuts <- c(0, 1, 5, 10, 30, 60, 90, Inf)

# plot distribution of session length
activations %>%
  filter(!is.na(avg_sesh_duration)) %>% 
  mutate(duration_bucket = cut(avg_sesh_duration, breaks = cuts)) %>% 
  filter(!is.na(duration_bucket)) %>% 
  group_by(activated_day1, duration_bucket) %>% 
  summarise(users = n_distinct(user_id)) %>%
  mutate(prop = users / sum(users)) %>% 
  buffplot(aes(x = duration_bucket, y = prop, fill = activated_day1)) +
  geom_col(show.legend = F) +
  facet_wrap(~activated_day1) +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) +
  labs(x = "First Session Duration", y = "Proportion of Users", 
       subtitle = "Activated on First Day")
```

```{r echo = FALSE, warning = FALSE, message = FALSE}
# define breakpoints
cuts <- c(0, 1, 5, 10, 30, 60, 90, Inf)

# plot distribution of session length
activations %>%
  filter(!is.na(avg_sesh_duration)) %>% 
  mutate(duration_bucket = cut(avg_sesh_duration, breaks = cuts)) %>% 
  filter(!is.na(duration_bucket)) %>% 
  group_by(duration_bucket, activated_day1) %>% 
  summarise(users = n_distinct(user_id)) %>%
  mutate(prop = users / sum(users)) %>% 
  filter(activated_day1) %>% 
  buffplot(aes(x = duration_bucket, y = prop)) +
  geom_col(show.legend = F) +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.5)) +
  labs(x = "First Session Duration", y = "Proportion of Users", 
       subtitle = "Activated on First Day")
```

We can see that there is a strong correlation between first session duration and the likelihood of activating on the first day.